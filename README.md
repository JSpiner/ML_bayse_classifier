# ML_bayse_classifier
SoftwareMaestro 과제 머신러닝

서버 주소(classifier) : http://40.74.112.15:8887/classifier  
소스코드 : https://github.com/JSpiner/ML_bayse_classifier  
랭크 이름 : 러닝 머신(bayse)-v0.0.2  러닝 머신(bayse)-v0.0.5    


# 구동방식
 
- 제공해주신 소스를 사용하지 않고 직접 베이즈 정리를 이용해 구현해보았습니다.
- 트리형태로 주어진 자료를 나눠서 카테고리를 구성하고
- 분류에 방해가 되는 단어들을 필터링 한 뒤
- KONLPY.Twitter 형태소 분석기를 이용해
- 상품명을 쪼개 배열에 담은 뒤 단어자체를 n_gram(2)하고 문장전체를 n_gram(1)하여 count하였습니다.
- 그 뒤 p = count / len(cates) 식을 개선해 smoothing 기법을 사용해
- p = log( (count + 1) / ( len(cates) + len(all_cates) )식을 이용해 계산했습니다.
 
 
# 추가로 시도해봤던 방식
 
1. 타 언어로 번역후 처리 -> 마이크로소프트 번역 api를 썼으나 timeout으로 인해 성능 평가를 제대로 하지 못했습니다.
2. 단어별 중요도 처리 -> 단어별 중요도를 빈도수에 따라 차등하여 count를 제곱하거나 곱하는 등의 시도를 했으나 추후 smoothing기법을 적용한 인식률이 더 좋았습니다.
3. 평가된 내용을 기반으로 랜덤 ->  로컬에서 테스트를 할 때 8:2의 비율로 train셋과 test셋을 나눠서 계산했는데 test셋으로 자체 평가 후 분류기가 낸 결과값을 카테고리별로 정리해서 특정 카테고리의 답이 나왔을때 이 답이 맞을 확률을 구해 다시 학습할때 랜덤을 돌려 해당 확률 안에 들면 결과값으로 나온 카테고리를 제외한 후 재분류를 했습니다. 정답이 틀린 카테고리는 일부 카테고리로 몰리지만 결과값이 다른 카테고리는 골고루 분포되있어 해당 방법으로는 평가점수가 더 떨어졌습니다.
4. 상중하 카테고리별로 차례로 분류 -> '상'카테고리만 맞을 확률이 80%가 넘는다는점에서 착안해 상 카테고리부터 분류 후 중 하로 내려가는 식으로 구성을 해봤으나 하위카테고리까지 포함후 처리했을댄 '상'카테고리가 맞을 확률이 80%였으나 패션과 가젼 두개만을 분류할때 정확도가 70% 미만이었고 밑으로 내려갈수록 점점더 확률이 내려갔습니다.
5. 많이 사용되는 단어는 제거 -> 모든 카테고리의 모든 제목별로 빈도수를 재서 상위 20% 단어는 무시하도록 만들어봤으나 인식률이 더 떨어졌습니다.
6. 이미지데이터 -> 이부분은 제가 cnn을 잘 몰라서그런지 직접 10000개의 데이터중 0byte인것을 제외하고 카테고리별로 cnn에넣어 학습을 시킨 후 이미지만으로 분류를 해봤더니 2%의 정확도가 나와 사용하지 않았습니다.
7. 인식되는 top3를 뽑아 재인식 -> 인식되는 top3를 추출하여 그것들간의 차가 크지 않을경우 재탐색을 했으나 오히려 확률이 낮아져 확인해보니 애초에 데이터셋중 잘못 입력되있는것들(예 : [TOKIO] 블렌드 보카시 테일러드 자켓 (브라운)_P013933835 -> 조끼로 분류되있음) 때문에 오히려 효과가 낮았습니다.
